# FMEA (Facial Micro-Expression Analysis) iOS App

FMEA is an iOS mobile application that performs **real-time facial micro-expression analysis** using **Core ML** and **Vision**.  
It was developed as part of my Final Year Project at **Nanyang Technological University (NTU)** to explore how AI can enhance **psychological therapy** by giving therapists deeper insights into their patientsâ€™ emotions.

Unlike traditional observation-based methods, FMEA analyzes subtle, involuntary facial movements (micro-expressions) that often reveal true emotionsâ€”even when individuals consciously suppress them.  

---

## ğŸ¯ Motivation & Objectives

Understanding genuine emotions is critical in psychotherapy, yet patients often conceal or mask them.  
FMEA bridges this gap by providing:

- **Objective emotional feedback** to complement therapistsâ€™ observations  
- **Real-time, on-device analysis** for privacy and responsiveness  
- **A user-friendly mobile app** deployable in clinical or telehealth contexts  

This project demonstrates how **AI + mobile technologies** can work together to support **mental health care**.

---

## ğŸ“± Features

- **Still Image Mode**  
  - Import a photo from the gallery  
  - Detects faces and classifies emotions with bounding boxes  

- **Live Feed Mode**  
  - Uses the iPhoneâ€™s front-facing camera  
  - Performs real-time face detection and emotion classification  
  - Displays bounding boxes and emotion labels directly on the feed  

- **Video Upload Mode**  
  - Upload videos from the photo library  
  - Choose a sampling rate (Low, Medium, High) to balance accuracy vs. speed  
  - Generates a detailed **Emotion Report**:
    - Pie chart of emotion distribution  
    - Duration and percentage of each emotion  
    - Video duration and sampling rate used  

---

## âš™ï¸ Tech Stack & Architecture

- **Language & Tools**
  - Swift 5, Xcode 16.2  
  - Runs on iOS 13+ (tested on iPhone 14, iOS 18.3.1)  

- **Frameworks & Libraries**
  - **SwiftUI + UIKit** â€“ UI design  
  - **Vision** â€“ Face detection & landmarks  
  - **CoreImage** â€“ Image preprocessing (grayscale, resizing, normalization)  
  - **CoreML** â€“ On-device CNN model for emotion classification  
  - **AVFoundation** â€“ Video capture & processing  
  - **PhotosUI** â€“ Image & video selection  
  - **Charts** â€“ Emotion distribution visualization  

- **Machine Learning**
  - CNN trained on **FER2013 dataset**  
  - Model conversion: TensorFlow â†’ Core ML (`coremltools`)  
  - Entirely on-device (no server needed â†’ better privacy, no latency)  

---

## ğŸ“‚ Project Structure

```
FMEA/
 â”œâ”€â”€ ContentView.swift        # Main entry screen
 â”œâ”€â”€ StillImage/              # Still image analysis feature
 â”œâ”€â”€ LiveFeed/                # Real-time camera feed feature
 â”œâ”€â”€ VideoUpload/             # Video upload + Emotion Report
 â”œâ”€â”€ FaceImageTool.swift      # Utilities for image preprocessing
 â”œâ”€â”€ MLCore.swift             # CoreML model integration
 â””â”€â”€ FMEA.xcodeproj           # Xcode project file
```

---

## ğŸš€ Getting Started

### Requirements
- macOS with **Xcode 16.2+**
- iPhone running **iOS 13+** (simulator not supported due to camera requirement)
- Camera & Photo Library permissions enabled

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/<YOUR_USERNAME>/FMEA.git
   cd FMEA
   ```
2. Open in Xcode:
   ```bash
   open FMEA.xcodeproj
   ```
3. Select your device â†’ Build & Run (**âŒ˜R**).

---

## ğŸ”® Future Work

- Explore **attention-based CNNs** (e.g., CBAM, Vision Transformers) to improve accuracy  
- Train on larger, more diverse datasets for robustness  
- Add therapist-focused features:
  - Session history & trend reports  
  - Exportable emotion logs  
  - Integration with telehealth platforms  

---

## ğŸ‘¨â€ğŸ’» About This Project

- Developed by: **Hsieh Boh Yang**  
- Degree: **BSc Computer Science, NTU (2025)**  
- Supervisor: **Prof. Zheng Jianmin**  

This project highlights my interests in:
- **AI/ML for healthcare**  
- **iOS app development (SwiftUI, CoreML, Vision)**  
- **Privacy-first on-device AI**  

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgements

- **NTU College of Computing and Data Science** for supporting this project  
- **Prof. Zheng Jianmin** for his guidance  
- Open-source contributors of **FER2013** and **DeepFace** models  
